################################################################  
# Container system settings
################################################################ 
COMPOSE_PROJECT_NAME=Home_Auto_AI
CONTAINERCONFIG="<Docker Container Path>"
PUID=(User id number)
PGID=(Docker Group id number)
TZ=Europe/London

################################################################  
# Container image versions
################################################################ 
CHESH_CAT_SW_VER=latest         # Cheshire cat
OLLAMA_SW_VER=rocm              # Ollama
PORTAINER_VER=latest            # Portainer
GALLOYDBOM_SW_VER=latest        # Google Alloy DB Omni
PRIVATEGPT=latest               # Private gpt AMD ROCM version

################################################################  
# Container services ports
################################################################  
PORTAINER_PORT=9002

################################################################  
# AlloyDB Omni 
################################################################  
PG_RAG=private_ai
priv_gpt_user=postgres
priv_gpt_pwd=<aplhanumeric password>

################################################################  
# Anything LLM
################################################################  
llm_provider='ollama'
embedding_model_pref='nomic-embed-text:latest'
ollama_base_path='http://ollama:11434'
ollama_model_pref='llama3'
ollama_model_token_limit='4096'
embedding_engine='ollama'
embedding_base_path='http://ollama:11434'
embedding_model_max_chunk_length='8192'
vector_db='qdrant'
qdrant_endpoint='http://anythingllm-vector-memory:6333'
disable_telemetry='true'
storage_dir='/app/server/storage'
server_port='3001'

################################################################  
# Cheshire Cat AI
################################################################
# Decide host and port for your Cat. Default will be localhost:1865
CCAT_CORE_HOST=localhost
CCAT_CORE_PORT=1865

# Decide to use https / wss secure protocols
# CCAT_CORE_USE_SECURE_PROTOCOLS=true

# Protect endpoints with an access token
# CCAT_API_KEY=meow

# self reload during development
# CCAT_DEBUG=true

# Log levels
# CCAT_LOG_LEVEL=INFO

# CORS
# CCAT_CORS_ALLOWED_ORIGINS=""

# Qdrant server
# CCAT_QDRANT_HOST=<host>
# CCAT_QDRANT_PORT=6333
# CCAT_QDRANT_API_KEY=<API_KEY>

# Turn on memory collections' snapshots on embedder change with SAVE_MEMORY_SNAPSHOTS=true
# CCAT_SAVE_MEMORY_SNAPSHOTS=false

# CONFIG_FILE
# CCAT_METADATA_FILE="cat/data/metadata.json"

################################################################  
# Private GPT
################################################################  
### local processing
# llm_mode=llamacpp
# llamacpp_llm_hf_repo_id="Cyborg-AI/mystral-hf-7b-v0.1.gguf"
# llamacpp_llm_hf_model_file="mystral-hf-7b-v0.1.gguf"
# llamacpp_embedding_hf_model_name="BAAI/bge-small-en-v1.5"
# llm_tokenizer=mistralai/Mistral-7B-Instruct-v0.2
# embedding_ingest_mode=parallel
# embedding_count_workers=4
# embedding_mode=huggingface
# huggingface_token=<hugginface token>
pgpt_profiles=local
run_setup=false

### Ollama settings
llm_mode=ollama 
ollama_api_base=http://ollama:11434
ollama_embedding_api_base=http://ollama:11434
ollama_llm_model=mistral # llama3:8b
ollama_embedding_model=BAAI/bge-small-en-v1.5 # nomic-embed-text
embedding_mode=ollama # huggingface 
embedding_ingest_mode=simple

### releated to postgress & ollama
embedding_embed_dim=384

### postgres rag
nodelistore_database=postgres
vectorstore_database=postgres
postgres_host=alloydbomni # - the postgres host address - Default=postgres
postgres_port=5432 # - the postgres port - Default=5432
postgres_database=$pg_rag # - the postgres database name - Default=postgres
postgres_user=$priv_gpt_user # - the postgres username - Default=postgres
postgres_password=$priv_gpt_pwd # - the postgres usernames password - Default=admin
postgres_schema_name=<schema name> # - the postgres schema name - Default=private_gpt

### rag extraction
rag_similarity_top_k=10
rag_rerank_enabled=true
rag_rerank_model=cross-encoder/ms-marco-MiniLM-L-2-v2
rag_rerank_top_n=5

