###############################################################
# Services
###############################################################
services:
  ################################################################  
  # Docker Management      
  ################################################################  
  # Docker Socket Proxy - Security Enchanced Proxy for Docker Socket
  socket-proxy:
    container_name: socket-proxy
    image: iamthefij/docker-socket-proxy
    restart: always
    networks:
      socket_proxy:
        ipv4_address: 192.168.91.253 # You can specify a static IP
    privileged: true
    ports:
      - "127.0.0.1:2375:2375" # Port 2375 should only ever get exposed to the internal network.
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    environment:
      - LOG_LEVEL=info # debug,info,notice,warning,err,crit,alert,emerg
      ## Variables match the URL prefix (i.e. AUTH blocks access to /auth/* parts of the API, etc.).
      # 0 to revoke access.
      # 1 to grant access.
      ## Granted by Default
      - EVENTS=1
      - PING=1
      - VERSION=1
      ## Revoked by Default
      # Security critical
      - AUTH=0
      - SECRETS=0
      - POST=1 # Watchtower, Authenthenik
      - DELETE=1 # Watchtower
        # GET Optons
      - BUILD=0
      - COMMIT=0
      - CONFIGS=0
      - CONTAINERS=1 # Traefik, portainer, Authenthenik, etc.
      - DISTRIBUTION=0
      - EXEC=0
      - IMAGES=1 # Portainer, Watchtower, Authenthenik
      - INFO=1 # Portainer, Authenthenik
      - NETWORKS=1 # Portainer, Watchtower
      - NODES=0
      - PLUGINS=0
      - SERVICES=1 # Portainer
      - SESSION=0
      - SWARM=0
      - SYSTEM=0
      - TASKS=1 # Portaienr
      - VOLUMES=1 # Portainer
      # POST Options
      - CONTAINERS_CREATE=1 # WatchTower
      - CONTAINERS_START=1 # WatchTower
      - CONTAINERS_UPDATE=1 # WatchTower
      # DELETE Options
      - CONTAINERS_DELETE=1 # WatchTower
      - IMAGES_DELETE=1 # WatchTower

  # Portainer - WebUI for Containers
  portainer:
    container_name: portainer
    image: portainer/portainer:$(PORTAINER_VER) # -ce:latest # linux-arm64 # = :latest
    restart: always
    # command: -H unix:///var/run/docker.sock # # Use Docker Socket Proxy instead for improved security
    # command: -H tcp://192.168.91.253 # appears to not work. Workaround was to create a new socket-proxymedia endpoint on portainer settings
    networks:
      ai_net:
      socket_proxy:
    ports:
      - "$PORTAINER_PORT:9000"
    expose:
      - "$PORTAINER_PORT"
    depends_on:
      - socket-proxy
    security_opt:
      - no-new-privileges:true
    volumes:
      # - /var/run/docker.sock:/var/run/docker.sock:ro # # Use Docker Socket Proxy instead for improved security
      - $CONTAINERCONFIG/authentik/certs:/certs
    environment:
      - TZ=$TZ

  # # ################################################################  
  # # # Database systems
  # # ################################################################        
  # Google alloydbomni Sql
  alloydbomni:
    image: google/alloydbomni 
    container_name: alloydbomni
    hostname: alloydbomni
    restart: unless-stopped
    networks:
      ai_net:
    volumes:
      - "alloydbomni_data:/var/lib/postgresql/data"
    environment:
      - PGDEBUG
      - POSTGRES_DB=$PG_RAG
      - POSTGRES_USER=$priv_gpt_user
      - POSTGRES_PASSWORD=$priv_gpt_pwd 

  cheshire-cat-vector-memory:
    image: qdrant/qdrant:latest
    container_name: cheshire_cat_vector_memory
    security_opt:
      - "seccomp=unconfined"
    volumes:
      - qdarant_vector:/qdrant/storage
    restart: unless-stopped
    networks:
      ai_net:
  
  anythingllm-vector-memory:
    image: qdrant/qdrant:latest
    container_name: anythingllm-vector-memory
    security_opt:
      - "seccomp=unconfined"
    volumes:
      - /mnt/data2/docker/anythingllm_q:/qdrant/storage
    restart: unless-stopped
    networks:
      ai_net:
  
  ###############################################################
  # AI
  ###############################################################
  ollama:
    image: ollama/ollama:rocm
    ports:
      - 7869:11434
    volumes:
      - ollama_config:/root/.ollama
    container_name: ollama
    security_opt:
      - "seccomp=unconfined"
    tty: true
    restart: always
    devices:
      - /dev/kfd
      - /dev/dri 
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0
      - HSA_OVERRIDE_GFX_VERSION=9.0.0
      - HSA_ENABLE_SDMA=0
    networks:
      ai_net:

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ollama_webui_config:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment: # https://docs.openwebui.com/getting-started/env-configuration#default_models
      - OLLAMA_BASE_URLS=http://ollama:7869 #comma separated ollama hosts
      - ENV=dev
      - WEBUI_AUTH=False
      - WEBUI_NAME=Manning Madness AI
      - WEBUI_URL=http://localhost:8080
      - WEBUI_SECRET_KEY=t0p-s3cr3t
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      ai_net:

  cheshire-cat-core:
    image: ghcr.io/cheshire-cat-ai/core:$(CHESH_CAT_SW_VER)
    container_name: cheshire_cat_core
    depends_on:
      - cheshire-cat-vector-memory
      - ollama
    security_opt:
      - "seccomp=unconfined"
    environment:
      - PYTHONUNBUFFERED=1
      - WATCHFILES_FORCE_POLLING=true
      - CORE_HOST=${CORE_HOST:-localhost}
      - CORE_PORT=${CORE_PORT:-1865}
      - QDRANT_HOST=${QDRANT_HOST:-cheshire_cat_vector_memory}
      - QDRANT_PORT=${QDRANT_PORT:-6333}
      - CORE_USE_SECURE_PROTOCOLS=${CORE_USE_SECURE_PROTOCOLS:-}
      - API_KEY=${API_KEY:-}
      - LOG_LEVEL=${LOG_LEVEL:-WARNING}
      - DEBUG=${DEBUG:-true}
      - SAVE_MEMORY_SNAPSHOTS=${SAVE_MEMORY_SNAPSHOTS:-false}
    ports:
      - ${CORE_PORT:-1865}:80
    volumes:
      - cat_static:/app/cat/static
      - cat_public:/app/cat/public
      - cat_plugins:/app/cat/plugins
      - /mnt/data2/docker/cheshire_cat/config/metadata.json:/app/data/metadata.json:rw
    command:
      - python
      - "-m"
      - "cat.main"
    restart: unless-stopped
    networks:
      ai_net: 
  
  privategpt:
    image: homeautomationmadness/private-gpt-amd-rocm:latest # privategptrocmdocker:latest
    container_name: privategpt
    devices:
      - /dev/kfd
      - /dev/dri 
    environment:
      ### Local Processing
      # LLAMACPP_LLM_HF_REPO_ID: $llamacpp_llm_hf_repo_id
      # LLAMACPP_LLM_HF_MODEL_FILE: $llamacpp_llm_hf_model_file
      # LLAMACPP_EMBEDDING_HF_MODEL_NAME: $llamacpp_embedding_hf_model_name
      # LLM_TOKENIZER: $llm_tokenizer
      # EMBEDDING_INGEST_MODE: $embedding_ingest_mode
      # EMBEDDING_COUNT_WORKERS: $embedding_count_workers
      # EMBEDDING_MODE: $embedding_mode
      # HUGGINGFACE_TOKEN: $huggingface_token
      PGPT_PROFILES: $pgpt_profiles
      RUN_SETUP: $run_setup
      ### Ollama settings
      LLM_MODE: $llm_mode
      OLLAMA_API_BASE: $ollama_api_base
      OLLAMA_EMBEDDING_API_BASE: $ollama_embedding_api_base
      OLLAMA_LLM_MODEL: $ollama_llm_model
      OLLAMA_EMBEDDING_MODEL: $ollama_embedding_model
      EMBEDDING_MODE: $embedding_mode
      EMBEDDING_INGEST_MODE: $embedding_ingest_mode
      ### Releated to Postgress & Ollama
      EMBEDDING_EMBED_DIM: $embedding_embed_dim
      # ### Postgres Rag
      NODESTORE_DATABASE: $nodelistore_database
      VECTORSTORE_DATABASE: $vectorstore_database
      POSTGRES_HOST: $postgress_host
      POSTGRES_PORT: $postgres_port
      POSTGRES_DATABASE: $pg_rag
      POSTGRES_USER: $priv_gpt_user
      POSTGRES_PASSWORD: $priv_gpt_pwd
      POSTGRES_SCHEMA_NAME: $postgres_schema_name # - the postgres schema name - Default: private_gpt
      ## RAG extraction
      RAG_SIMILARITY_TOP_K: $rag_similarity_top_k
      RAG_RERANK_ENABLED: $rag_rerank_enabled
      RAG_RERANK_MODEL: $rag_rerank_model
      RAG_RERANK_TOP_N: $rag_rerank_top_n
      ### sYSTEM STUFF
      PUID: $PUID
      PGID: $PGID
      TZ: $TZ
    volumes:
      - privategpt_data:/home/worker/app/local_data
      - privategpt_models:/home/worker/app/models
    ports:
      - 8197:8080/tcp
    networks:
      ai_net:

  anything-llm:
    container_name: anything-llm
    image: mintplexlabs/anythingllm
    cap_add:
      - SYS_ADMIN
    volumes:
      - ".env:/app/server/.env"
      - "/mnt/data2/docker/anythingllm/server/storage/:/app/server/storage"
      - "/mnt/data2/docker/anythingllm/collector/hotdir/:/app/collector/hotdir"
      - "/mnt/data2/docker/anythingllm/collector/outputs/:/app/collector/outputs"
    user: "${PUID:-1000}:${PGID:-1000}"
    ports:
      - "3001:3001"
    environment:
      LLM_PROVIDER: $llm_provider
      EMBEDDING_MODEL_PREF: $embedding_model_pref
      OLLAMA_BASE_PATH: $ollama_base_path
      OLLAMA_MODEL_PREF: $ollama_model_pref
      OLLAMA_MODEL_TOKEN_LIMIT: $ollama_model_token_limit
      EMBEDDING_ENGINE: $embedding_engine
      EMBEDDING_BASE_PATH: $embedding_base_path
      EMBEDDING_MODEL_MAX_CHUNK_LENGTH: $embedding_model_max_chunk_length
      VECTOR_DB: $vector_db
      QDRANT_ENDPOINT: $qdrant_endpoint
      DISABLE_TELEMETRY: $disable_telemetry
      STORAGE_DIR: $storage_dir
      SERVER_PORT: $server_port
    networks:
      ai_net:

###############################################################
# Networks
###############################################################
networks:
  socket_proxy:
    name: socket_proxy
    driver: bridge
    ipam: # You can specify the subnet for each network, directly or using env variables
      config:
        - subnet: 192.168.91.0/24
  
  ai_net:
    external: false 
    name: ai_net
    driver: bridge

###############################################################
# Volumes
###############################################################
volumes:
  
  alloydbomni_data:
    driver: local
    name: alloydbomni_data
    driver_opts:
      type: 'none'
      o: 'bind'
      device: '$CONTAINERCONFIG/alloydbomni/data'

  ollama_config:
    driver: local
    name: ollama_config
    driver_opts:
      type: 'none'
      o: 'bind'
      device: '$CONTAINERCONFIG/ollama/config'
  
  ollama_webui_config:
    driver: local
    name: ollama_webui_config
    driver_opts:
      type: 'none'
      o: 'bind'
      device: '$CONTAINERCONFIG/ollama_webui_config/config/'

  privategpt_models:
    driver: local
    name: privategpt_models
    driver_opts:
      type: 'none'
      o: 'bind'
      device: '$CONTAINERCONFIG/privategpt/models/'

  privategpt_data:
    driver: local
    name: privategpt_data
    driver_opts:
      type: 'none'
      o: 'bind'
      device: '$CONTAINERCONFIG/privategpt/data/'